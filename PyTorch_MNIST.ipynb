{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを用意する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_setを用意 [(入力データ, ラベル), ....,(入力データ, ラベル)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST('~/images/ml_images/mnist', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = MNIST('~/images/ml_images/mnist', train=False, download=True, transform=transforms.ToTensor())\n",
    "# transforms.ToTensor() について\n",
    "# Convert a PIL Image or numpy.ndarray to tensor.\n",
    "# Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \n",
    "# if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706, 0.4941, 0.5333,\n",
       "         0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176,\n",
       "         0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "         0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333,\n",
       "         0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9843,\n",
       "         0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8588,\n",
       "         0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137, 0.9686, 0.9451,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137,\n",
       "         0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000, 0.1686, 0.6039,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275, 0.4235, 0.0039,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922, 0.9922, 0.4667,\n",
       "         0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294, 0.9922, 0.9922,\n",
       "         0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.3647, 0.9882,\n",
       "         0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9765,\n",
       "         0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098, 0.7176, 0.9922,\n",
       "         0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922, 0.9922, 0.9922,\n",
       "         0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922, 0.9922, 0.7882,\n",
       "         0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902,\n",
       "         0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.3176, 0.0078,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706, 0.8588,\n",
       "         0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922, 0.9922,\n",
       "         0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922, 0.8314,\n",
       "         0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 中身をみてみるとたしかに 2次元で要素は[0~1]範囲の数値になっている ん、リストは3次元か。モノクロだからかな？？そうかも。\n",
    "train_data[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a9db6d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADolJREFUeJzt3X2MXOV1x/HfyXq9jo1JvHVsHOJgxzgBYhqTjgzICFwhXKdCMqgCYkWRQ5M4LzgprStBraq4FancKiF1CUVamq1tifcEiv+gSZAVAVFhy+IQXuLwErMli7e7mA3YEOKX3dM/9m60MTvPrGfuzJ3d8/1I1szcc+/co4Hf3pl55t7H3F0A4nlP0Q0AKAbhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1LRG7my6tfkMzWrkLoFQfqu3dcQP20TWrSn8ZrZG0jZJLZL+3d23ptafoVk61y6uZZcAErp894TXrfptv5m1SLpF0qcknSVpnZmdVe3zAWisWj7zr5D0krvvc/cjku6StDaftgDUWy3hP1XSr8Y87s2W/R4z22Bm3WbWfVSHa9gdgDzVEv7xvlR41/nB7t7h7iV3L7WqrYbdAchTLeHvlbRwzOMPSdpfWzsAGqWW8D8haamZLTaz6ZI+LWlXPm0BqLeqh/rc/ZiZbZT0Q40M9XW6+3O5dQagrmoa53f3ByU9mFMvABqIn/cCQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVE2z9JpZj6RDkoYkHXP3Uh5NIT82Lf2fuOUDc+u6/+f/elHZ2tDM4eS2py0ZSNZnftWS9f+7aXrZ2p7S3cltDwy9nayfe++mZP30v3o8WW8GNYU/88fufiCH5wHQQLztB4KqNfwu6Udm9qSZbcijIQCNUevb/pXuvt/M5kl6yMx+4e6PjF0h+6OwQZJmaGaNuwOQl5qO/O6+P7sdkHS/pBXjrNPh7iV3L7WqrZbdAchR1eE3s1lmNnv0vqTVkp7NqzEA9VXL2/75ku43s9HnucPdf5BLVwDqrurwu/s+SZ/IsZcpq+XMpcm6t7Um6/sven+y/s555cek29+XHq9+9BPp8e4i/ddvZifr//SdNcl619l3lK29fPSd5LZb+y9J1j/4qCfrkwFDfUBQhB8IivADQRF+ICjCDwRF+IGg8jirL7yhVZ9M1m/afkuy/tHW8qeeTmVHfShZ/7ubP5esT3s7Pdx2/r0by9Zmv3osuW3bgfRQ4MzurmR9MuDIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc6fg7bn9yfrT/52YbL+0db+PNvJ1aa+85L1fW+lL/29fcn3ytbeHE6P08//1/9O1utp8p+wWxlHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IytwbN6J5srX7uXZxw/bXLAavPj9ZP7gmfXntlqdPStZ/9tWbT7inUTce+MNk/YmL0uP4Q2+8maz7+eWv7t7z9eSmWrzuZ+kV8C5dvlsHfTA9d3mGIz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBFVxnN/MOiVdKmnA3Zdly9ol3S1pkaQeSVe6+68r7SzqOH8lLXP/IFkfen0wWX/5jvJj9c9d2JncdsU/fi1Zn3dLcefU48TlPc6/XdLxE6FfL2m3uy+VtDt7DGASqRh+d39E0vGHnrWSdmT3d0i6LOe+ANRZtZ/557t7nyRlt/PyawlAI9T9Gn5mtkHSBkmaoZn13h2ACar2yN9vZgskKbsdKLeiu3e4e8ndS61qq3J3APJWbfh3SVqf3V8v6YF82gHQKBXDb2Z3SnpM0sfMrNfMPi9pq6RLzOxFSZdkjwFMIhU/87v7ujIlBuxzMnTg9Zq2P3pwetXbfvwzP0/WX7u1Jf0Ew0NV7xvF4hd+QFCEHwiK8ANBEX4gKMIPBEX4gaCYonsKOPO6F8rWrj47PSL7H6ftTtYvuuKaZH323Y8n62heHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+aeA1DTZr3/lzOS2r+x6J1m//sadyfrfXHl5su4/fV/Z2sJvPJbcVg2cPj4ijvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTFKbrzxBTdzWfwz89P1m+/4ZvJ+uJpM6re98d3bkzWl97Wl6wf29dT9b6nqryn6AYwBRF+ICjCDwRF+IGgCD8QFOEHgiL8QFAVx/nNrFPSpZIG3H1ZtmyLpC9Kei1bbbO7P1hpZ4zzTz6+cnmyfvLW3mT9zo/8sOp9n/HjLyTrH/v78tcxkKShF/dVve/JKu9x/u2S1oyz/Nvuvjz7VzH4AJpLxfC7+yOSBhvQC4AGquUz/0Yze9rMOs1sTm4dAWiIasN/q6QlkpZL6pP0rXIrmtkGM+s2s+6jOlzl7gDkrarwu3u/uw+5+7Ck2yStSKzb4e4ldy+1qq3aPgHkrKrwm9mCMQ8vl/RsPu0AaJSKl+42szslrZI018x6Jd0gaZWZLZfkknokfamOPQKoA87nR01a5s9L1vdfdXrZWtd125LbvqfCG9PPvLw6WX/zgteT9amI8/kBVET4gaAIPxAU4QeCIvxAUIQfCIqhPhTmnt70FN0zbXqy/hs/kqxf+rVryz/3/V3JbScrhvoAVET4gaAIPxAU4QeCIvxAUIQfCIrwA0FVPJ8fsQ1fkL509y+vSE/RvWx5T9lapXH8Sm4ePCdZn/lAd03PP9Vx5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnn+KstCxZf+Hr6bH221buSNYvnJE+p74Wh/1osv744OL0Ewz35djN1MORHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjjOb2YLJe2UdIqkYUkd7r7NzNol3S1pkaQeSVe6+6/r12pc0xaflqz/8uoPlq1tuequ5LZ/dtKBqnrKw+b+UrL+8LbzkvU5O9LX/UfaRI78xyRtcvczJZ0n6RozO0vS9ZJ2u/tSSbuzxwAmiYrhd/c+d9+T3T8kaa+kUyWtlTT6868dki6rV5MA8ndCn/nNbJGkcyR1SZrv7n3SyB8ISfPybg5A/Uw4/GZ2kqTvS7rW3Q+ewHYbzKzbzLqP6nA1PQKogwmF38xaNRL82939vmxxv5ktyOoLJA2Mt627d7h7yd1LrWrLo2cAOagYfjMzSd+VtNfdbxpT2iVpfXZ/vaQH8m8PQL1M5JTelZI+K+kZM3sqW7ZZ0lZJ95jZ5yW9IumK+rQ4+U1b9OFk/c0/WpCsX/UPP0jWv/z++5L1etrUlx6Oe+zfyg/ntW//n+S2c4YZyquniuF3959IKjff98X5tgOgUfiFHxAU4QeCIvxAUIQfCIrwA0ERfiAoLt09QdMWnFK2Ntg5K7ntVxY/nKyvm91fVU952PjqBcn6nlvTU3TP/d6zyXr7IcbqmxVHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IKsw4/5E/SV8m+shfDibrm09/sGxt9XvfrqqnvPQPvVO2duGuTcltz/jbXyTr7W+kx+mHk1U0M478QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUmHH+nsvSf+deOPveuu37ljeWJOvbHl6drNtQuSunjzjjxpfL1pb2dyW3HUpWMZVx5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoMzd0yuYLZS0U9IpGjl9u8Pdt5nZFklflPRatupmdy9/0rukk63dzzVm9Qbqpct366APpn8YkpnIj3yOSdrk7nvMbLakJ83soaz2bXf/ZrWNAihOxfC7e5+kvuz+ITPbK+nUejcGoL5O6DO/mS2SdI6k0d+MbjSzp82s08zmlNlmg5l1m1n3UR2uqVkA+Zlw+M3sJEnfl3Stux+UdKukJZKWa+SdwbfG287dO9y95O6lVrXl0DKAPEwo/GbWqpHg3+7u90mSu/e7+5C7D0u6TdKK+rUJIG8Vw29mJum7kva6+01jli8Ys9rlktLTtQJoKhP5tn+lpM9KesbMnsqWbZa0zsyWS3JJPZK+VJcOAdTFRL7t/4mk8cYNk2P6AJobv/ADgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVfHS3bnuzOw1Sf87ZtFcSQca1sCJadbemrUvid6qlWdvp7n7ByayYkPD/66dm3W7e6mwBhKatbdm7Uuit2oV1Rtv+4GgCD8QVNHh7yh4/ynN2luz9iXRW7UK6a3Qz/wAilP0kR9AQQoJv5mtMbPnzewlM7u+iB7KMbMeM3vGzJ4ys+6Ce+k0swEze3bMsnYze8jMXsxux50mraDetpjZq9lr95SZ/WlBvS00sx+b2V4ze87M/iJbXuhrl+irkNet4W/7zaxF0guSLpHUK+kJSevc/ecNbaQMM+uRVHL3wseEzexCSW9J2unuy7Jl/yxp0N23Zn8457j7dU3S2xZJbxU9c3M2ocyCsTNLS7pM0udU4GuX6OtKFfC6FXHkXyHpJXff5+5HJN0laW0BfTQ9d39E0uBxi9dK2pHd36GR/3karkxvTcHd+9x9T3b/kKTRmaULfe0SfRWiiPCfKulXYx73qrmm/HZJPzKzJ81sQ9HNjGN+Nm366PTp8wru53gVZ25upONmlm6a166aGa/zVkT4x5v9p5mGHFa6+yclfUrSNdnbW0zMhGZubpRxZpZuCtXOeJ23IsLfK2nhmMcfkrS/gD7G5e77s9sBSfer+WYf7h+dJDW7HSi4n99pppmbx5tZWk3w2jXTjNdFhP8JSUvNbLGZTZf0aUm7CujjXcxsVvZFjMxslqTVar7Zh3dJWp/dXy/pgQJ7+T3NMnNzuZmlVfBr12wzXhfyI59sKONfJLVI6nT3bzS8iXGY2Uc0crSXRiYxvaPI3szsTkmrNHLWV7+kGyT9p6R7JH1Y0iuSrnD3hn/xVqa3VRp56/q7mZtHP2M3uLcLJD0q6RlJw9nizRr5fF3Ya5foa50KeN34hR8QFL/wA4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1P8D6+E2hIAP97kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0-1の範囲だから pltでimshowをして画像化して確認してみる\n",
    "# やっぱり画像のリストは3次元だった\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(train_data[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data_loader を使って data_setを指定バッチごとに読み込めるようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  train_loader を使ってバッチごとまとめて読み込む\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 一つだけ取り出して中身をみてみる\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = data_iter.next()\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "# matplotlibで1つ目のデータを可視化してみる\n",
    "npimg = images[0].numpy()\n",
    "npimg = npimg.reshape((28, 28))\n",
    "plt.imshow(npimg, cmap='gray')\n",
    "print('Label:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12ae6d630>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n",
      "torch.Size([4, 784])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([4, 1, 28, 28])\n",
      "torch.Size([4, 784])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# データの形を確認する\n",
    "# 4つのバッチごとにセットになっている\n",
    "j = 0\n",
    "for i in train_loader:\n",
    "    print(i[0].size())\n",
    "    print(i[0].view(-1, 28*28).size())\n",
    "    print(i[0].view(-1, 28*28))\n",
    "#     print(i)\n",
    "    j += 1\n",
    "    if j == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNのモデルを定義する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのクラスを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # これつかってなくない？？\n",
    "\n",
    "# nn.Module: Base class for all neural network modules.\n",
    "# Your models should also subclass this class.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # nn.Linear Applies a linear transformation to the incoming data: y = xA^T + b\n",
    "        self.l1 = nn.Linear(28 * 28, 50) # 入力層から隠れ層へ\n",
    "        self.l2 = nn.Linear(50, 10) # 隠れ層から出力層へ\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # view は　\"Returns a new tensor with the same data as the self tensor but of a different shape.\"\n",
    "        # -1はいいように推測してくれるという意味\n",
    "        x = x.view(-1, 28 * 28) # テンソルのリサイズ: (N, 1, 28, 28) --> (N, 784)\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Liner層の働きの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Input data ----------\n",
      "torch.Size([5, 2])\n",
      "tensor([[ 1.8041,  1.4401],\n",
      "        [ 0.3086,  0.0552],\n",
      "        [ 2.0938,  0.8977],\n",
      "        [-0.8610, -1.2958],\n",
      "        [ 0.9452, -1.1976]])\n",
      "---------- output data ----------\n",
      "torch.Size([5, 3])\n",
      "tensor([[-0.0772,  1.5103, -1.3282],\n",
      "        [ 0.3034,  0.7916, -0.1832],\n",
      "        [ 0.1271,  1.8306, -1.2471],\n",
      "        [ 0.6930,  0.2894,  0.8125],\n",
      "        [ 0.7733,  1.5090,  0.0178]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# nn.Liner example\n",
    "m = nn.Linear(2, 3)\n",
    "input = torch.randn(5, 2)\n",
    "print('---------- Input data ----------')\n",
    "print(input.size())\n",
    "print(input)\n",
    "output = m(input)\n",
    "print('---------- output data ----------')\n",
    "print(output.size())\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コスト関数と最適化手法の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コスト関数と最適化手法を定義\n",
    "import torch.optim as optim\n",
    "\n",
    "# This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コスト関数のCrosEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CrosEntropyLossの計算式の確認\n",
    "The loss can be described as:\n",
    "\n",
    "$\n",
    "        \\text{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right)\n",
    "                       = -x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogSoftmaxの計算式の確認\n",
    "Applies the $\\log(\\text{Softmax}(x))$ function to an n-dimensional\n",
    "    input Tensor. The LogSoftmax formulation can be simplified as:\n",
    "\n",
    "$\n",
    "\\text{LogSoftmax}(x_{i}) = \\log\\left(\\frac{\\exp(x_i) }{ \\sum_j \\exp(x_j)} \\right)\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6472, -0.2271, -0.0744],\n",
      "        [-0.7669,  1.3740,  0.0398]])\n",
      "tensor([[-1.4575, -1.0374, -0.8848],\n",
      "        [-2.4636, -0.3228, -1.6569]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kapi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "m = nn.LogSoftmax()\n",
    "input = torch.randn(2, 3)\n",
    "print(input)\n",
    "output = m(input)\n",
    "print(output)\n",
    "\n",
    "# ええと確認してみるか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5235, 0.7968, 0.9283],\n",
       "        [0.4645, 3.9509, 1.0406]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# おお、こんな便利なものがある\n",
    "input.exp()\n",
    "# こっちでもいいらしい\n",
    "# torch.exp(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9487,  0.6469])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# やっぱりこういうのあるよね、そりゃ\n",
    "torch.sum( input, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 入力をtorch.autograd.Variableに変換\n",
    "2. 逆伝播で使う勾配情報をリセット\n",
    "3. 順伝播\n",
    "4. ロスの計算\n",
    "5. 逆伝播\n",
    "6. 得られた勾配を使ってパラメータを更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[JupyterまたはiPython Notebookでデバッグをする方法 \\- Qiita](https://qiita.com/makopo/items/170c939c79dcc5c89e12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000 loss: 1.056\n",
      "1 2000 loss: 0.452\n",
      "1 3000 loss: 0.389\n",
      "1 4000 loss: 0.427\n",
      "1 5000 loss: 0.340\n",
      "1 6000 loss: 0.341\n",
      "1 7000 loss: 0.336\n",
      "1 8000 loss: 0.376\n",
      "1 9000 loss: 0.310\n",
      "1 10000 loss: 0.337\n",
      "1 11000 loss: 0.328\n",
      "1 12000 loss: 0.341\n",
      "1 13000 loss: 0.317\n",
      "1 14000 loss: 0.320\n",
      "1 15000 loss: 0.231\n",
      "2 1000 loss: 0.289\n",
      "2 2000 loss: 0.287\n",
      "2 3000 loss: 0.298\n",
      "2 4000 loss: 0.351\n",
      "2 5000 loss: 0.274\n",
      "2 6000 loss: 0.301\n",
      "2 7000 loss: 0.296\n",
      "2 8000 loss: 0.329\n",
      "2 9000 loss: 0.277\n",
      "2 10000 loss: 0.314\n",
      "2 11000 loss: 0.304\n",
      "2 12000 loss: 0.315\n",
      "2 13000 loss: 0.296\n",
      "2 14000 loss: 0.300\n",
      "2 15000 loss: 0.214\n",
      "3 1000 loss: 0.275\n",
      "3 2000 loss: 0.273\n",
      "3 3000 loss: 0.281\n",
      "3 4000 loss: 0.337\n",
      "3 5000 loss: 0.261\n",
      "3 6000 loss: 0.291\n",
      "3 7000 loss: 0.285\n",
      "3 8000 loss: 0.313\n",
      "3 9000 loss: 0.267\n",
      "3 10000 loss: 0.305\n",
      "3 11000 loss: 0.295\n",
      "3 12000 loss: 0.305\n",
      "3 13000 loss: 0.287\n",
      "3 14000 loss: 0.290\n",
      "3 15000 loss: 0.206\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # バッチサイズごとに処理をする 今は4にした\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Variableに変換 これ何しているのか？？\n",
    "        # もうこれdeprecatedになっている\n",
    "#         inputs, labels = Variable(inputs), Variable(labels)\n",
    "#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "\n",
    "        # 勾配情報をリセット\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 順伝播\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # コスト関数を使ってロスを計算する\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 逆伝播 ここで、微分係数を計算している?\n",
    "        # ええと、もう一度NNのアルゴリズムのところ見直そう、、\n",
    "        loss.backward()\n",
    "        \n",
    "        # パラメータの更新\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data.item()\n",
    "        \n",
    "        # 60000データあるので、15000回で全部のデータをまわしたことになる\n",
    "        if i % 1000 == 999:\n",
    "            print('%d %d loss: %.3f' % (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backwardでは何をしているのか？？\n",
    "# ネットワークなくても、backwardできているんだけど、どういうことなん？\n",
    "# 変数を保持しているということ？？\n",
    "# うん、nnはただのモジュールだから"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5090, -0.3406, -0.9058,  0.5428,  0.6961],\n",
      "        [-1.3489, -0.9710,  0.3438, -1.0301, -0.3680],\n",
      "        [-0.2126, -0.2919,  0.9350,  1.4719, -0.4875]])\n",
      "tensor([1, 4, 0])\n",
      "tensor(2.1648)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-f5bd9b6aef7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "input = torch.randn(3, 5, requires_grad=False)\n",
    "print(input)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5202],\n",
       "        [-0.6813]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [10]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2], [10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6472, -0.2271, -0.0744],\n",
       "        [-0.7669,  1.3740,  0.0398]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3236, -0.1136, -0.0372],\n",
       "        [-0.0767,  0.1374,  0.0040]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# なるほど。やっぱりこういうことできるんだな！！\n",
    "input/torch.tensor([[2.], [10.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1615,  0.1687, -0.0254,  0.1288, -1.2359],\n",
      "        [-0.3305, -0.2392,  1.3431, -0.6825,  0.1191],\n",
      "        [ 0.0048, -0.9204,  1.1814, -0.3697, -0.2038]], requires_grad=True)\n",
      "tensor([0, 1, 1])\n",
      "softmax tensor([[-1.6516, -1.3214, -1.5155, -1.3613, -2.7260],\n",
      "        [-2.2719, -2.1806, -0.5983, -2.6238, -1.8223],\n",
      "        [-1.8147, -2.7399, -0.6381, -2.1892, -2.0233]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor(2.1907, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1907, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kapi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "sm = nn.LogSoftmax() \n",
    "\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target)\n",
    "\n",
    "out1 = sm(input)\n",
    "print(\"softmax\", out1)\n",
    "\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 9113 / 10000 = 0.000000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in test_loader:\n",
    "    inputs, labels = data\n",
    "    outputs = net(Variable(inputs))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy %d / %d = %f' % (correct, total, correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_iter = iter(test_loader)\n",
    "\n",
    "inputs, labels = test_iter.next()\n",
    "outputs = net(Variable(inputs))\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "plt.imshow(inputs[0].numpy().reshape(28, 28), cmap='gray')\n",
    "print('Label:', predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
